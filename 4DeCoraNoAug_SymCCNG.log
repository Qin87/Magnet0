cuda:2
Namespace(withAug=False, AugDirect=20, method_name='SymDiGCN', seed=100, IsDirectedData=False, dataset='WebKB/texas', undirect_dataset='Cora', MakeImbalance=True, CustomizeMask=False, K=2, heads=8, log_root='../logs/', log_path='test', data_path='../dataset/data/tmp/', epochs=1500, num_filter=2, p_q=0.95, p_inter=0.1, dropout=0.0, debug=False, new_setting=False, layer=2, lr=0.005, l2=0.0005, to_undirected=False, alpha=0.1, randomseed=-1, imb_ratio=100, n_layer=2, feat_dim=64, warmup=5, epoch=900, tau=2, max=False, no_mask=False, gdc='ppr')
excel_file_path is  FalseAug_SymDiGCN_Cora_output.xlsx
12-04-19:54:09
Dataset is  Cora() 
Chosen from DirectedData:  False
Num of bidrected edges: 5278, total num of edges: 10556
This is directed graph:  False
data_x torch.Size([2708, 1433])
cuda:2
0
mu  cpu cpu
cuda:2
Traceback (most recent call last):
  File "/home/qj2004/magnet/src/GNNChangeTrainTest.py", line 592, in <module>
    main(args)
  File "/home/qj2004/magnet/src/GNNChangeTrainTest.py", line 405, in main
    data.edge_index, edge_in, in_weight, edge_out, out_weight = F_in_out(edges,
  File "/home/qj2004/magnet/src/utils/preprocess.py", line 239, in F_in_out
    a = sp.coo_matrix((np.ones(len(edge_index[0])), edge_index), shape=(size, size)).tocsc()
  File "/home/qj2004/.conda/envs/myenv/lib/python3.10/site-packages/scipy/sparse/_coo.py", line 163, in __init__
    idx_dtype = self._get_index_dtype((row, col), maxval=max(self.shape), check_contents=True)
  File "/home/qj2004/.conda/envs/myenv/lib/python3.10/site-packages/scipy/sparse/_base.py", line 1289, in _get_index_dtype
    return get_index_dtype(arrays, maxval, (check_contents and not self._is_array))
  File "/home/qj2004/.conda/envs/myenv/lib/python3.10/site-packages/scipy/sparse/_sputils.py", line 183, in get_index_dtype
    arr = np.asarray(arr)
  File "/home/qj2004/.conda/envs/myenv/lib/python3.10/site-packages/torch/_tensor.py", line 757, in __array__
    return self.numpy()
TypeError: can't convert cuda:2 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
